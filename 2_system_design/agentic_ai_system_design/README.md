---
title: "Agentic AI System Design"
category: system-design
levels: ["senior", "principal"]
skills: [agents, tool-use, memory-management, orchestration, eval-frameworks]
questions:
  "mid": ["What is the difference between a Chain and an Agent?"]
  "senior": ["Design a system where multiple agents collaborate to write a software feature."]
  "principal": ["How do you handle cyclic dependencies and infinite loops in autonomous agent workflows?"]
---

# Agentic AI System Design

## ðŸ’¡ Core Ideas

Designing systems for Agents is fundamentally different from standard microservices or even ML inference services. Agents are **stateful**, **non-deterministic**, and **long-running**.

*   **State Management**: Agents need "Memory".
    *   **Short-term**: Context window (conversation history).
    *   **Long-term**: Vector Database (episodic memory) or SQL (structured user data).
*   **Tool Execution Environment**:
    *   **Sandboxing**: Code generated by agents (e.g., Python for data analysis) MUST run in a sandbox (Docker/WebAssembly) to prevent security risks.
*   **Orchestration Patterns**:
    *   **Router**: A central "Brain" decides which sub-agent to call.
    *   **State Machine (Graph)**: Define explicit nodes and edges (LangGraph). Best for controlling complex flows to avoid "going off the rails".
    *   **Swarm**: Decentralized agents broadcasting messages (Actor Model).
    *   **Reflection**: Agent critiques its own output before maximizing quality.
    *   **Planning**:
        *   **ReAct**: Reason, Act, Reason.
        *   **Tree of Thoughts (ToT)**: Explore multiple reasoning branches.

### 4. Evaluation Frameworks
How do you measure a non-deterministic agent?
*   **LLM-as-a-Judge**: Use a stronger model (GPT-4) to grade the traces of a smaller agent.
*   **RAGAS**: Measures retrieval quality.
*   **Trajectory Evaluation**: Measuring if the agent took the optimal path (fewest steps) to the solution.

## ðŸ“š Resources

*   [**Building effective agents**](https://www.anthropic.com/research/building-effective-agents) - Anthropic's guide.
*   [**LangGraph Documentation**](https://langchain-ai.github.io/langgraph/) - For graph-based agent design.
*   [**E2B**](https://e2b.dev/) - Sandboxed cloud environments for AI agents.

## ðŸ› ï¸ Practice

### Project 1: Customer Support Triage
Design a system where a "Triage Agent" analyzes an email, tags it (Billing/Technical/Sales), and routes it to a specialized sub-agent.
*   **Goal**: Implement this using a State Graph (nodes = agents, edges = conditional jumps).

### Project 2: Code Interpreter Sandbox
Build a safe execution environment.
*   **Goal**: An API that accepts Python code string, spins up a Docker container, runs the code with a timeout, and returns stdout/stderr.

## ðŸ—£ï¸ Interview Questions

### Senior-Level
*   **Q**: How do you prevent an Agent from getting stuck in a loop (e.g., repeating the same tool call)?
*   **A**:
    1.  **Max Iterations**: Hard limit on the loop count.
    2.  **History Inspection**: Check if the last N tool calls are identical.
    3.  **Temperature Bump**: Temporarily increase temperature to force exploration.
    4.  **Meta-Prompting**: Inject a system prompt "You seem stuck. Try a different approach."
*   **Q**: Discuss security implications of allowing agents to execute code.
*   **A**: Agents can execute code in a sandboxed environment (e.g., Docker) to prevent security risks.

### Principal-Level
*   **Q**: Design the infrastructure for a "Devin-like" autonomous coding agent that runs for hours.
*   **A**:
    *   **Compute**: Spot instances aren't great due to interruptions. Use durable VMs.
    *   **State**: Snapshot the filesystem and agent state (memory/messages) periodically to S3 to allow resuming after failure.
    *   **VNC/Browser**: Provide the agent with a headless browser and terminal view (multimodal input).
    *   **Cost Control**: Real-time budget tracking (token usage + compute time). Kill switch if budget > $5.
