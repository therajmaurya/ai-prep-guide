---
title: "Natural Language Processing (NLP)"
category: must
levels: ["mid", "senior"]
skills: [nlp, tokenization, embeddings]
questions:
  "mid": ["What is Word2Vec?"]
  "senior": ["Explain the architecture of the Transformer model."]
---

# Natural Language Processing (NLP)

## Core Ideas
- Tokenization (BPE, WordPiece).
- Word Embeddings (GloVe, Word2Vec).
- RNNs, LSTMs, GRUs.
- Attention Mechanism and Transformers.

## Resources
- [Stanford CS224n](http://web.stanford.edu/class/cs224n/)
- [Hugging Face Course](https://huggingface.co/course/chapter1/1)

## Practice
- Fine-tune BERT for sentiment analysis.
- Implement a simple chatbot using an RNN.

## Questions
### Mid Level
- What is the difference between stemming and lemmatization?

### Senior Level
- Discuss the trade-offs between encoder-only, decoder-only, and encoder-decoder architectures.
